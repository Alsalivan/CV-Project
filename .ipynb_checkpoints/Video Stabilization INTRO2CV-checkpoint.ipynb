{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Stabilization Using Point Feature Matching in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is an implementation of algorithm of Point Feature Matching.\n",
    "\n",
    "* We used original [paper.](https://www.researchgate.net/publication/321589788_Video_Stabilization_Using_Point_Feature_Matching)\n",
    "\n",
    "* We decided to use our own small (~5 videos) database of shaky videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The larger the more stable the video, but less reactive to sudden panning\n",
    "SMOOTHING_RADIUS=50 \n",
    "\n",
    "# Read input video\n",
    "cap = cv2.VideoCapture('video2.mp4') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params for video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame count\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    " \n",
    "# Get width and height of video stream\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Get frames per second (fps)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    " \n",
    "# Define the codec for output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up output video\n",
    "out = cv2.VideoWriter('video_out.avi', fourcc, fps, (2 * w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frames and Tracked points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0/250 -  Tracked points : 200\n",
      "Frame: 1/250 -  Tracked points : 200\n",
      "Frame: 2/250 -  Tracked points : 200\n",
      "Frame: 3/250 -  Tracked points : 200\n",
      "Frame: 4/250 -  Tracked points : 200\n",
      "Frame: 5/250 -  Tracked points : 200\n",
      "Frame: 6/250 -  Tracked points : 200\n",
      "Frame: 7/250 -  Tracked points : 200\n",
      "Frame: 8/250 -  Tracked points : 200\n",
      "Frame: 9/250 -  Tracked points : 200\n",
      "Frame: 10/250 -  Tracked points : 200\n",
      "Frame: 11/250 -  Tracked points : 200\n",
      "Frame: 12/250 -  Tracked points : 200\n",
      "Frame: 13/250 -  Tracked points : 200\n",
      "Frame: 14/250 -  Tracked points : 200\n",
      "Frame: 15/250 -  Tracked points : 200\n",
      "Frame: 16/250 -  Tracked points : 200\n",
      "Frame: 17/250 -  Tracked points : 200\n",
      "Frame: 18/250 -  Tracked points : 200\n",
      "Frame: 19/250 -  Tracked points : 200\n",
      "Frame: 20/250 -  Tracked points : 200\n",
      "Frame: 21/250 -  Tracked points : 200\n",
      "Frame: 22/250 -  Tracked points : 200\n",
      "Frame: 23/250 -  Tracked points : 200\n",
      "Frame: 24/250 -  Tracked points : 200\n",
      "Frame: 25/250 -  Tracked points : 200\n",
      "Frame: 26/250 -  Tracked points : 200\n",
      "Frame: 27/250 -  Tracked points : 200\n",
      "Frame: 28/250 -  Tracked points : 200\n",
      "Frame: 29/250 -  Tracked points : 200\n",
      "Frame: 30/250 -  Tracked points : 200\n",
      "Frame: 31/250 -  Tracked points : 200\n",
      "Frame: 32/250 -  Tracked points : 200\n",
      "Frame: 33/250 -  Tracked points : 200\n",
      "Frame: 34/250 -  Tracked points : 200\n",
      "Frame: 35/250 -  Tracked points : 200\n",
      "Frame: 36/250 -  Tracked points : 200\n",
      "Frame: 37/250 -  Tracked points : 200\n",
      "Frame: 38/250 -  Tracked points : 200\n",
      "Frame: 39/250 -  Tracked points : 200\n",
      "Frame: 40/250 -  Tracked points : 200\n",
      "Frame: 41/250 -  Tracked points : 200\n",
      "Frame: 42/250 -  Tracked points : 200\n",
      "Frame: 43/250 -  Tracked points : 200\n",
      "Frame: 44/250 -  Tracked points : 200\n",
      "Frame: 45/250 -  Tracked points : 200\n",
      "Frame: 46/250 -  Tracked points : 200\n",
      "Frame: 47/250 -  Tracked points : 200\n",
      "Frame: 48/250 -  Tracked points : 200\n",
      "Frame: 49/250 -  Tracked points : 200\n",
      "Frame: 50/250 -  Tracked points : 200\n",
      "Frame: 51/250 -  Tracked points : 200\n",
      "Frame: 52/250 -  Tracked points : 200\n",
      "Frame: 53/250 -  Tracked points : 200\n",
      "Frame: 54/250 -  Tracked points : 200\n",
      "Frame: 55/250 -  Tracked points : 200\n",
      "Frame: 56/250 -  Tracked points : 200\n",
      "Frame: 57/250 -  Tracked points : 200\n",
      "Frame: 58/250 -  Tracked points : 200\n",
      "Frame: 59/250 -  Tracked points : 200\n",
      "Frame: 60/250 -  Tracked points : 200\n",
      "Frame: 61/250 -  Tracked points : 200\n",
      "Frame: 62/250 -  Tracked points : 200\n",
      "Frame: 63/250 -  Tracked points : 200\n",
      "Frame: 64/250 -  Tracked points : 200\n",
      "Frame: 65/250 -  Tracked points : 200\n",
      "Frame: 66/250 -  Tracked points : 200\n",
      "Frame: 67/250 -  Tracked points : 200\n",
      "Frame: 68/250 -  Tracked points : 200\n",
      "Frame: 69/250 -  Tracked points : 200\n",
      "Frame: 70/250 -  Tracked points : 200\n",
      "Frame: 71/250 -  Tracked points : 200\n",
      "Frame: 72/250 -  Tracked points : 200\n",
      "Frame: 73/250 -  Tracked points : 200\n",
      "Frame: 74/250 -  Tracked points : 200\n",
      "Frame: 75/250 -  Tracked points : 200\n",
      "Frame: 76/250 -  Tracked points : 200\n",
      "Frame: 77/250 -  Tracked points : 200\n",
      "Frame: 78/250 -  Tracked points : 200\n",
      "Frame: 79/250 -  Tracked points : 200\n",
      "Frame: 80/250 -  Tracked points : 200\n",
      "Frame: 81/250 -  Tracked points : 200\n",
      "Frame: 82/250 -  Tracked points : 200\n",
      "Frame: 83/250 -  Tracked points : 200\n",
      "Frame: 84/250 -  Tracked points : 200\n",
      "Frame: 85/250 -  Tracked points : 200\n",
      "Frame: 86/250 -  Tracked points : 200\n",
      "Frame: 87/250 -  Tracked points : 200\n",
      "Frame: 88/250 -  Tracked points : 200\n",
      "Frame: 89/250 -  Tracked points : 200\n",
      "Frame: 90/250 -  Tracked points : 200\n",
      "Frame: 91/250 -  Tracked points : 200\n",
      "Frame: 92/250 -  Tracked points : 200\n",
      "Frame: 93/250 -  Tracked points : 200\n",
      "Frame: 94/250 -  Tracked points : 200\n",
      "Frame: 95/250 -  Tracked points : 200\n",
      "Frame: 96/250 -  Tracked points : 200\n",
      "Frame: 97/250 -  Tracked points : 200\n",
      "Frame: 98/250 -  Tracked points : 200\n",
      "Frame: 99/250 -  Tracked points : 200\n",
      "Frame: 100/250 -  Tracked points : 200\n",
      "Frame: 101/250 -  Tracked points : 200\n",
      "Frame: 102/250 -  Tracked points : 200\n",
      "Frame: 103/250 -  Tracked points : 200\n",
      "Frame: 104/250 -  Tracked points : 200\n",
      "Frame: 105/250 -  Tracked points : 200\n",
      "Frame: 106/250 -  Tracked points : 200\n",
      "Frame: 107/250 -  Tracked points : 200\n",
      "Frame: 108/250 -  Tracked points : 200\n",
      "Frame: 109/250 -  Tracked points : 200\n",
      "Frame: 110/250 -  Tracked points : 200\n",
      "Frame: 111/250 -  Tracked points : 199\n",
      "Frame: 112/250 -  Tracked points : 199\n",
      "Frame: 113/250 -  Tracked points : 200\n",
      "Frame: 114/250 -  Tracked points : 200\n",
      "Frame: 115/250 -  Tracked points : 200\n",
      "Frame: 116/250 -  Tracked points : 200\n",
      "Frame: 117/250 -  Tracked points : 200\n",
      "Frame: 118/250 -  Tracked points : 200\n",
      "Frame: 119/250 -  Tracked points : 200\n",
      "Frame: 120/250 -  Tracked points : 200\n",
      "Frame: 121/250 -  Tracked points : 200\n",
      "Frame: 122/250 -  Tracked points : 200\n",
      "Frame: 123/250 -  Tracked points : 200\n",
      "Frame: 124/250 -  Tracked points : 200\n",
      "Frame: 125/250 -  Tracked points : 200\n",
      "Frame: 126/250 -  Tracked points : 200\n",
      "Frame: 127/250 -  Tracked points : 200\n",
      "Frame: 128/250 -  Tracked points : 200\n",
      "Frame: 129/250 -  Tracked points : 200\n",
      "Frame: 130/250 -  Tracked points : 200\n",
      "Frame: 131/250 -  Tracked points : 200\n",
      "Frame: 132/250 -  Tracked points : 200\n",
      "Frame: 133/250 -  Tracked points : 200\n",
      "Frame: 134/250 -  Tracked points : 200\n",
      "Frame: 135/250 -  Tracked points : 200\n",
      "Frame: 136/250 -  Tracked points : 200\n",
      "Frame: 137/250 -  Tracked points : 200\n",
      "Frame: 138/250 -  Tracked points : 200\n",
      "Frame: 139/250 -  Tracked points : 200\n",
      "Frame: 140/250 -  Tracked points : 200\n",
      "Frame: 141/250 -  Tracked points : 200\n",
      "Frame: 142/250 -  Tracked points : 200\n",
      "Frame: 143/250 -  Tracked points : 200\n",
      "Frame: 144/250 -  Tracked points : 200\n",
      "Frame: 145/250 -  Tracked points : 200\n",
      "Frame: 146/250 -  Tracked points : 200\n",
      "Frame: 147/250 -  Tracked points : 200\n",
      "Frame: 148/250 -  Tracked points : 200\n",
      "Frame: 149/250 -  Tracked points : 200\n",
      "Frame: 150/250 -  Tracked points : 200\n",
      "Frame: 151/250 -  Tracked points : 200\n",
      "Frame: 152/250 -  Tracked points : 200\n",
      "Frame: 153/250 -  Tracked points : 200\n",
      "Frame: 154/250 -  Tracked points : 200\n",
      "Frame: 155/250 -  Tracked points : 200\n",
      "Frame: 156/250 -  Tracked points : 200\n",
      "Frame: 157/250 -  Tracked points : 200\n",
      "Frame: 158/250 -  Tracked points : 200\n",
      "Frame: 159/250 -  Tracked points : 200\n",
      "Frame: 160/250 -  Tracked points : 200\n",
      "Frame: 161/250 -  Tracked points : 200\n",
      "Frame: 162/250 -  Tracked points : 200\n",
      "Frame: 163/250 -  Tracked points : 200\n",
      "Frame: 164/250 -  Tracked points : 200\n",
      "Frame: 165/250 -  Tracked points : 200\n",
      "Frame: 166/250 -  Tracked points : 200\n",
      "Frame: 167/250 -  Tracked points : 200\n",
      "Frame: 168/250 -  Tracked points : 200\n",
      "Frame: 169/250 -  Tracked points : 200\n",
      "Frame: 170/250 -  Tracked points : 200\n",
      "Frame: 171/250 -  Tracked points : 200\n",
      "Frame: 172/250 -  Tracked points : 200\n",
      "Frame: 173/250 -  Tracked points : 200\n",
      "Frame: 174/250 -  Tracked points : 200\n",
      "Frame: 175/250 -  Tracked points : 200\n",
      "Frame: 176/250 -  Tracked points : 200\n",
      "Frame: 177/250 -  Tracked points : 200\n",
      "Frame: 178/250 -  Tracked points : 200\n",
      "Frame: 179/250 -  Tracked points : 200\n",
      "Frame: 180/250 -  Tracked points : 200\n",
      "Frame: 181/250 -  Tracked points : 200\n",
      "Frame: 182/250 -  Tracked points : 200\n",
      "Frame: 183/250 -  Tracked points : 200\n",
      "Frame: 184/250 -  Tracked points : 200\n",
      "Frame: 185/250 -  Tracked points : 200\n",
      "Frame: 186/250 -  Tracked points : 200\n",
      "Frame: 187/250 -  Tracked points : 200\n",
      "Frame: 188/250 -  Tracked points : 200\n",
      "Frame: 189/250 -  Tracked points : 200\n",
      "Frame: 190/250 -  Tracked points : 200\n",
      "Frame: 191/250 -  Tracked points : 200\n",
      "Frame: 192/250 -  Tracked points : 200\n",
      "Frame: 193/250 -  Tracked points : 200\n",
      "Frame: 194/250 -  Tracked points : 200\n",
      "Frame: 195/250 -  Tracked points : 200\n",
      "Frame: 196/250 -  Tracked points : 200\n",
      "Frame: 197/250 -  Tracked points : 200\n",
      "Frame: 198/250 -  Tracked points : 200\n",
      "Frame: 199/250 -  Tracked points : 200\n",
      "Frame: 200/250 -  Tracked points : 200\n",
      "Frame: 201/250 -  Tracked points : 200\n",
      "Frame: 202/250 -  Tracked points : 200\n",
      "Frame: 203/250 -  Tracked points : 200\n",
      "Frame: 204/250 -  Tracked points : 200\n",
      "Frame: 205/250 -  Tracked points : 200\n",
      "Frame: 206/250 -  Tracked points : 200\n",
      "Frame: 207/250 -  Tracked points : 200\n",
      "Frame: 208/250 -  Tracked points : 200\n",
      "Frame: 209/250 -  Tracked points : 200\n",
      "Frame: 210/250 -  Tracked points : 200\n",
      "Frame: 211/250 -  Tracked points : 200\n",
      "Frame: 212/250 -  Tracked points : 200\n",
      "Frame: 213/250 -  Tracked points : 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 214/250 -  Tracked points : 200\n",
      "Frame: 215/250 -  Tracked points : 200\n",
      "Frame: 216/250 -  Tracked points : 200\n",
      "Frame: 217/250 -  Tracked points : 200\n",
      "Frame: 218/250 -  Tracked points : 200\n",
      "Frame: 219/250 -  Tracked points : 200\n",
      "Frame: 220/250 -  Tracked points : 200\n",
      "Frame: 221/250 -  Tracked points : 200\n",
      "Frame: 222/250 -  Tracked points : 200\n",
      "Frame: 223/250 -  Tracked points : 200\n",
      "Frame: 224/250 -  Tracked points : 200\n",
      "Frame: 225/250 -  Tracked points : 200\n",
      "Frame: 226/250 -  Tracked points : 200\n",
      "Frame: 227/250 -  Tracked points : 200\n",
      "Frame: 228/250 -  Tracked points : 200\n",
      "Frame: 229/250 -  Tracked points : 200\n",
      "Frame: 230/250 -  Tracked points : 200\n",
      "Frame: 231/250 -  Tracked points : 200\n",
      "Frame: 232/250 -  Tracked points : 200\n",
      "Frame: 233/250 -  Tracked points : 200\n",
      "Frame: 234/250 -  Tracked points : 200\n",
      "Frame: 235/250 -  Tracked points : 200\n",
      "Frame: 236/250 -  Tracked points : 200\n",
      "Frame: 237/250 -  Tracked points : 200\n",
      "Frame: 238/250 -  Tracked points : 200\n",
      "Frame: 239/250 -  Tracked points : 200\n",
      "Frame: 240/250 -  Tracked points : 200\n",
      "Frame: 241/250 -  Tracked points : 200\n",
      "Frame: 242/250 -  Tracked points : 200\n",
      "Frame: 243/250 -  Tracked points : 200\n",
      "Frame: 244/250 -  Tracked points : 200\n",
      "Frame: 245/250 -  Tracked points : 200\n",
      "Frame: 246/250 -  Tracked points : 200\n",
      "Frame: 247/250 -  Tracked points : 200\n"
     ]
    }
   ],
   "source": [
    "# Read first frame\n",
    "_, prev = cap.read() \n",
    " \n",
    "# Convert frame to grayscale\n",
    "prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# Pre-define transformation-store array\n",
    "transforms = np.zeros((n_frames-1, 3), np.float32) \n",
    "\n",
    "for i in range(n_frames-2):\n",
    "    \n",
    "    # Detect feature points in previous frame\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray,\n",
    "                                     maxCorners=200,\n",
    "                                     qualityLevel=0.01,\n",
    "                                     minDistance=30,\n",
    "                                     blockSize=3)\n",
    "\n",
    "    # Read next frame\n",
    "    success, curr = cap.read() \n",
    "    if not success: \n",
    "        break \n",
    "\n",
    "    # Convert to grayscale\n",
    "    curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Calculate optical flow (i.e. track feature points)\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None) \n",
    "\n",
    "    # Sanity check\n",
    "    assert prev_pts.shape == curr_pts.shape \n",
    "\n",
    "    # Filter only valid points\n",
    "    idx = np.where(status==1)[0]\n",
    "    prev_pts = prev_pts[idx]\n",
    "    curr_pts = curr_pts[idx]\n",
    "\n",
    "    #Find transformation matrix\n",
    "    m = cv2.estimateRigidTransform(prev_pts, curr_pts, fullAffine=False) \n",
    "    \n",
    "    # Extract traslation\n",
    "    dx = m[0,2]\n",
    "    dy = m[1,2]\n",
    "\n",
    "    # Extract rotation angle\n",
    "    da = np.arctan2(m[1,0], m[0,0])\n",
    "\n",
    "    # Store transformation\n",
    "    transforms[i] = [dx,dy,da]\n",
    "\n",
    "    # Move to next frame\n",
    "    prev_gray = curr_gray\n",
    "\n",
    "    print(\"Frame: \" + str(i) +  \"/\" + str(n_frames) + \" -  Tracked points : \" + str(len(prev_pts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute trajectory using cumulative sum of transformations\n",
    "trajectory = np.cumsum(transforms, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(curve, radius): \n",
    "    window_size = 2 * radius + 1\n",
    "    # Define the filter \n",
    "    f = np.ones(window_size)/window_size \n",
    "    # Add padding to the boundaries \n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), 'edge') \n",
    "    # Apply convolution \n",
    "    curve_smoothed = np.convolve(curve_pad, f, mode='same') \n",
    "    # Remove padding \n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    # return smoothed curve\n",
    "    return curve_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(trajectory): \n",
    "    smoothed_trajectory = np.copy(trajectory) \n",
    "    # Filter the x, y and angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = movingAverage(trajectory[:,i], radius=SMOOTHING_RADIUS)\n",
    "\n",
    "    return smoothed_trajectory\n",
    "\n",
    "# Create variable to store smoothed trajectory\n",
    "smoothed_trajectory = smooth(trajectory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in smoothed_trajectory and trajectory\n",
    "difference = smoothed_trajectory - trajectory\n",
    " \n",
    "# Calculate newer transformation array\n",
    "transforms_smooth = transforms + difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixBorder(frame):\n",
    "    s = frame.shape\n",
    "    # Scale the image 4% without moving the center\n",
    "    T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.04)\n",
    "    frame = cv2.warpAffine(frame, T, (s[1], s[0]))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset stream to first frame \n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n",
    " \n",
    "# Write n_frames-1 transformed frames\n",
    "for i in range(n_frames-2):\n",
    "    # Read next frame\n",
    "    success, frame = cap.read() \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Extract transformations from the new transformation array\n",
    "    dx = transforms_smooth[i,0]\n",
    "    dy = transforms_smooth[i,1]\n",
    "    da = transforms_smooth[i,2]\n",
    "\n",
    "    # Reconstruct transformation matrix accordingly to new values\n",
    "    m = np.zeros((2,3), np.float32)\n",
    "    m[0,0] = np.cos(da)\n",
    "    m[0,1] = -np.sin(da)\n",
    "    m[1,0] = np.sin(da)\n",
    "    m[1,1] = np.cos(da)\n",
    "    m[0,2] = dx\n",
    "    m[1,2] = dy\n",
    "\n",
    "    # Apply affine wrapping to the given frame\n",
    "    frame_stabilized = cv2.warpAffine(frame, m, (w,h))\n",
    "\n",
    "    # Fix border artifacts\n",
    "    frame_stabilized = fixBorder(frame_stabilized) \n",
    "\n",
    "    # Write the frame to the file\n",
    "    frame_out = cv2.hconcat([frame, frame_stabilized])\n",
    "\n",
    "    # If the image is too big, resize it.\n",
    "    if(frame_out.shape[1] > 1920): \n",
    "        frame_out = cv2.resize(frame_out, (int(frame_out.shape[1]/2), int(frame_out.shape[0]/2)))\n",
    "\n",
    "    cv2.imshow(\"Before and After\", frame_out)\n",
    "    cv2.waitKey(10)\n",
    "    out.write(frame_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8c2053d96e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Release video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Close windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# Release video\n",
    "cap.release()\n",
    "out.release()\n",
    "# Close windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
